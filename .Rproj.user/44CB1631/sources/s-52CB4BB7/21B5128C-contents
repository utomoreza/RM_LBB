---
title: "Regression Model for Predicting Wine Quality"
author: "Reza Dwi Utomo"
date: "15/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This notebook aims to accomplish [Regression Model](https://algorit.ma/course/regression-models/) course at Algoritma. The dataset used is obtained from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Wine+Quality), i.e. Wine Quality Data Set. The dataset will be used to predict wine quality.

### Dataset Background

The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult: [Web Link](http://www.vinhoverde.pt/en/) or the reference [Cortez et al., 2009](http://dx.doi.org/10.1016/j.dss.2009.05.016). Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).

These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.

### Aim

The goal is to model wine quality based on physicochemical tests.

### Objectives

1. To solve the final model equation

2. To output the statistical values (adjusted) R-squared and Root Mean Squared Error (RMSE)

3. To examine the model including statistics and visualizations:

+ Assess linearity of model (parameters)
+ Assess serial independence of errors
+ Assess heteroscedasticity
+ Assess normality of residual distribution
+ Assess multicollinearity

4. To interpretate the model

5. To consider other factors, such as:

+ Are there any outliers?
+ Are there missing values?
+ How will categorical variables be handled?

6. To test the model using dataset test and discuss the results

### Metadata

There are 12 columns available in the dataset. They are briefly described below or you can read in [this file](winequality.names). For more information, read [Cortez et al., 2009](http://dx.doi.org/10.1016/j.dss.2009.05.016).

Input variables (based on physicochemical tests):

1. fixed acidity
2. volatile acidity
3. citric acid
4. residual sugar
5. chlorides
6. free sulfur dioxide
7. total sulfur dioxide
8. density
9. pH
10. sulphates
11. alcohol

Output variable (based on sensory data):

12. quality (score between 0 and 10)

### Source

Paulo Cortez, University of Minho, Guimar√£es, Portugal, http://www3.dsi.uminho.pt/pcortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal @2009

### Relevant Papers

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. *Modeling wine preferences by data mining from physicochemical properties*. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

Available at: [Web Link](http://dx.doi.org/10.1016/j.dss.2009.05.016)

## Preparation

Prepare the performance indicators.

```{r}
library(MLmetrics)
indicator <- function(model, y_pred, y_true) {
     adj.r.sq <- summary(model)$adj.r.squared
     mse <- MSE(y_pred, y_true)
     rmse <- RMSE(y_pred, y_true)
     mae <- MAE(y_pred, y_true)
     print(paste0("Adjusted R-squared: ", round(adj.r.sq, 4)))
     print(paste0("MSE: ", round(mse, 4)))
     print(paste0("RMSE: ", round(rmse, 4)))
     print(paste0("MAE: ", round(mae, 4)))
}

CheckNormal <- function(model) {
     hist(model$residuals, breaks = 30)
     shaptest <- shapiro.test(model$residuals)
     print(shaptest)
     if (shaptest$p.value <= 0.05) {
          print("H0 rejected: the residuals are NOT distributed normally")
     } else {
          print("H0 failed to reject: the residuals ARE distributed normally")
     }
}

library(lmtest)
CheckHomos <- function(model){
     plot(model$fitted.values, model$residuals)
     abline(h = 0, col = "red")
     BP <- bptest(model)
     if (BP$p.value <= 0.05) {
          print("H0 rejected: Error variance spreads INCONSTANTLY/generating patterns (Heteroscedasticity)")
     } else {
          print("H0 failed to reject: Error variance spreads CONSTANTLY (Homoscedasticity)")
     }
}

library(tidyverse)
library(car)
library(psych)
CheckCollinear <- function(dataset, model){
     dataset %>% select(-quality) %>% pairs.panels()
     vif(model)
}
```

```{r}
redDF <- read.csv("winequality-red.csv", sep = ";")
whiteDF <- read.csv("winequality-white.csv", sep = ";")
redDF
whiteDF
```

```{r}
redDF %>% is.na() %>% colSums()
whiteDF %>% is.na() %>% colSums()
```

Perfect. Since the used datasets are originally clean, we will not find any missing value. So, let's move on to explore the data.

## Exploratory Data Analysis

### Exploring Red Wine Dataset

#### Using Boxplots

```{r}
redDF %>% pivot_longer(cols = c(1:11), names_to = "Params", values_to = "Value") %>% 
     ggplot(aes(x = Params,
                y = Value,
                fill = Params)) +
     geom_boxplot(show.legend = F) +
     coord_flip()
```

dadada

#### Using Scatter Plots, Correlation, and p-value

```{r}
# library(psych)
# pairs.panels(redDF)

# library(ggcorrplot)
# ggcorrplot(redDF %>% cor(),
#   hc.order = TRUE, type = "lower",
#   lab = TRUE,
#   digits = 1,
#   ggtheme = ggplot2::theme_dark(),
# )

library(PerformanceAnalytics)
chart.Correlation(redDF, hist = T)
```

The preceding figure tells many things. But, in general, it shows four points: scatter plots between each variable, histograms of each variable, correlation values between each value, and p-values between each value against significance value of 0.05.

     1. Scatter plots

Surprisingly, we found something interesting here. The scatter plots of between `quality` and each predictor variable form the same pattern that the target variable `quality` classifies the values into several classess, i.e. 3, 4, 5, 6, 7, and 8. To examine this case, we will go through to assess linear regression to model the data.

Moreover, there are several predictors which have strong relationship, e.g. between `fixed.acidity` and `citric.acid`. They are indicated by their tendency to have inclined or declined line. This case is discussed further in the Correlation values point below.

     2. Histograms
     
Each predictor variable show value distributed appropriately. However, the target variable exhibits poor distribution. This supports the above finding from scatter plots analysis. We could check the summary of such variable to make sure.

```{r}
summary(redDF$quality)
table(redDF$quality)
```

Unsuprisingly, `quality` does have classified values. **Based on this finding, it seems that linear regression is not suitable for this dataset. This is our initial hypothesis.**

     3. Correlation values

The figure above shows that below relationships have a strong correlation. This also can be seen

     - Between `density` and `fixed.acidity` (0.67)
     - Between `fixed.acidity` and `citric.acid` (0.67)
     - Between `fixed.acidity` and `pH` (-0.68)
     - Between `free.sulfur.dioxide` and `total.sulfur.dioxide` (0.67)
     
Those perhaps indicate sufficiently high multicollinearity. We will highlight this issue and discuss it later in the [model for red wine](#Model-for-Red-Wine).

     4. P-values

In addition, it is only `volatile.acidity` and `alcohol` which have the largest correlation value with `quality`. However, we also need to check the Pearson's correlation test based on the p-value. As seen in the figure above, the red stars in the upper triangle of the matrix indicate the significance. The more the stars exist, the more significant the relationship is. In order to be significant enough to the significance value (we use significance value (alpha) of 0.05), we need at least one star.

In this p-value analysis, we're only interested in considering the p-values of relationship between `quality` and each predictor variable. We can see that all variables have at least one star (meaning p-value less than pre-determined alpha (i.e. 0.05)), except `residual.sugar`. So, we won't consider such variable any longer. You could move on to [red wine modelling](#Model-for-Red-Wine) if you wouldn't like to read exploring white wine dataset below.

### Exploring White Wine Dataset

#### Using Boxplots

```{r}
whiteDF %>% pivot_longer(cols = c(1:11), names_to = "Params", values_to = "Value") %>% 
     ggplot(aes(x = Params,
                y = Value,
                fill = Params)) +
     geom_boxplot(show.legend = F) +
     coord_flip()
```

- Using Scatter Plots

```{r}
# ScatPlot <- function(X) {
#      Xi <- X %>% select(-quality)
#      for (i in 1:ncol(Xi)) {
#           plot(Xi[,i], X$quality, 
#                main = paste0("quality vs ", names(redDF[i])),
#                xlab = names(redDF[i]),
#                ylab = "quality")
#      }
# }
# 
# ScatPlot(whiteDF)
```


- Using Correlation

```{r}
# ggcorrplot(whiteDF %>% cor(),
#   hc.order = TRUE, type = "lower",
#   lab = TRUE,
#   digits = 1,
#   ggtheme = ggplot2::theme_dark(),
# )
```

Most variables have little correlation with `quality`. It is only `alcohol` that has slightly large correlation value, i.e. 0.4. However, in order to make sure, we need to perform Pearson's correlation test.

```{r}
# CorTest(whiteDF)
```

There are only two variable which are not significant, i.e. `free.sulfur.dioxide` and `citric.acid`. So, we will remove them from `whiteDF`.

```{r}
# whiteDF1 <- whiteDF %>% select(-c(free.sulfur.dioxide, citric.acid))
# whiteDF1
```

### Modelling

#### Splitting Train Datasets and Test Datasets

80% of data for train datasets
20% of data for test datasets

```{r}
set.seed(1)
sampleSize <- round(nrow(redDF)*0.8)
idx <- sample(seq_len(sampleSize), size = sampleSize)

X.train_red <- redDF[idx,]
X.test_red <- redDF[-idx,]
```

```{r}
# set.seed(2)
# sampleSize <- round(nrow(whiteDF1)*0.8)
# idx <- sample(seq_len(sampleSize), size = sampleSize)
# 
# X.train_white <- whiteDF1[idx,]
# X.test_white <- whiteDF1[-idx,]
```

#### Model for Red Wine

- Create the model

As mentioned in [red wine exploratory data analysis](#Using-Scatter-Plots,-Correlation,-and-p-value), we will employ all predictor variables, except `residual.sugar`, for the model. Let's create linear model from those variables.

```{r}
model_red1 <- lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol, 
                 data = X.train_red)
summary(model_red1)
```

From the `summary()` function above, it can be seen that approximately a half number of all predictor variables exhibits insignificance. Furthermore, the adjusted R-squared also performs poor result. Before we tackle with this issue, we should check the assumptions of the model.

- Check the assumptions

Since the linearity assumption has been discussed earlier in [this section](#Using-Scatter-Plots,-Correlation,-and-p-value), here, we're going to use three assumptions, i.e. normality, homoscedasticity, and multicollinearity.

     + Normality
     
By employing normality assumption, we'd like to have the residuals of the predicted value to approach the normal distribution. We can check this by plotting the residuals and using Shapiro-Wilk normality test. For the latter, we desire to have p-value more than significance value (i.e. 0.05) so that the null hypothesis is failed to reject.

In the [Preparation](#Preparation) chapter, we have declared a function to carry out this task called `CheckNormal()`. So, let's use it.
     
```{r}
CheckNormal(model = model_red1)
```

Although it seems the figure above indicates that the residuals tend to gather around 0 number (i.e. approaching to have normal distribution), we are unable to immediately believe this. We also have to check the results of Shapiro-Wilk normality test. And unfortunately, in the case of normality, our model shows poor results. The p-value is so small that H0 is rejected, meaning that the residuals is **not** distributed normally.

     + Homoscedasticity

```{r}
CheckHomos(model = model_red1)
```

     + Multicollinearity

```{r}
CheckCollinear(dataset = redDF, model = model_red1)
```

#### Red Wine Model Improvements



- Check the Performances

```{r}
indicator(model = model_red1, y_pred = model_red1$fitted.values, y_true = X.train_red$quality)
```

```{r}
set.seed(1)
sampleSize <- round(nrow(redDF)*0.8)
idx <- sample(seq_len(sampleSize), size = sampleSize)

X.train_redAll <- redDF[idx,]
# X.test_redAll <- redDF[-idx,]

model_redOne <- lm(quality ~ 1, data = X.train_redAll)
model_redAll <- lm(quality ~ ., data = X.train_redAll)
summary(model_redOne)
summary(model_redAll)
```

```{r}
step(object = model_redAll, direction = "backward", trace = F)
```

```{r}
model.back_redAll <- lm(formula = quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + 
    total.sulfur.dioxide + pH + sulphates + alcohol, data = X.train_redAll)
summary(model.back_redAll)
```

```{r}
step(object = model_redAll, 
     scope = list(lower = model_redOne, upper = model_redAll),
     direction = "forward", trace = F)
```

```{r}
model.forw_redAll <- lm(formula = quality ~ fixed.acidity + volatile.acidity + citric.acid + 
    residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + 
    density + pH + sulphates + alcohol, data = X.train_redAll)
summary(model.forw_redAll)
```

```{r}
step(object = model_redAll, 
     scope = list(lower = model_redOne, upper = model_redAll),
     direction = "both", trace = F)
```

```{r}
model.both_redAll <- lm(formula = quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + 
    total.sulfur.dioxide + pH + sulphates + alcohol, data = X.train_redAll)
summary(model.both_redAll)
```



#### Model for White Wine

## Model Improvements